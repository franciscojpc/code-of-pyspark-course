{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afe5cc4-8c2f-457b-8abd-fa3d69dd3163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWarning\u001b[39m\u001b[22m: Your Pipfile requires \u001b[39m\u001b[1mpython_version\u001b[39m\u001b[22m \u001b[36m\u001b[22m3.7\u001b[39m\u001b[22m, but you are using \u001b[36m\u001b[22m3.8.10\u001b[39m\u001b[22m (\u001b[32m\u001b[22m/home/paco/.local/share/v/P/bin/python\u001b[39m\u001b[22m).\n",
      "  \u001b[32m\u001b[22m$ pipenv --rm\u001b[39m\u001b[22m and rebuilding the virtual environment may resolve the issue.\n",
      "  \u001b[33m\u001b[22m$ pipenv check\u001b[39m\u001b[22m will surely fail.\n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mpyspark\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mpyspark\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h‚úî Installation Succeeded\u001b[0m \n",
      "\u001b[33m\u001b[1mPipfile.lock (904bfd) out of date, updating to (c2ee98)...\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[33m\u001b[22m[dev-packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies...\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[33m\u001b[22m[packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies...\u001b[39m\u001b[22m\n",
      "\u001b[KBuilding requirements...\n",
      "\u001b[KResolving dependencies...\n",
      "\u001b[K\u001b[?25h\u001b[32m\u001b[22m‚úî Success!\u001b[39m\u001b[22m\u001b[0m \n",
      "\u001b[39m\u001b[1mUpdated Pipfile.lock (c2ee98)!\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (c2ee98)...\u001b[39m\u001b[22m\n",
      "  üêç   \u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m 0/0 ‚Äî \u001b[30m\u001b[22m00:00:00\u001b[39m\u001b[22m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf7a85f-e661-4ccb-95d5-2fd332f275a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6bc083-f789-4d51-a02a-429febc7e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWarning\u001b[39m\u001b[22m: Your Pipfile requires \u001b[39m\u001b[1mpython_version\u001b[39m\u001b[22m \u001b[36m\u001b[22m3.7\u001b[39m\u001b[22m, but you are using \u001b[36m\u001b[22m3.8.10\u001b[39m\u001b[22m (\u001b[32m\u001b[22m/home/paco/.local/share/v/P/bin/python\u001b[39m\u001b[22m).\n",
      "  \u001b[32m\u001b[22m$ pipenv --rm\u001b[39m\u001b[22m and rebuilding the virtual environment may resolve the issue.\n",
      "  \u001b[33m\u001b[22m$ pipenv check\u001b[39m\u001b[22m will surely fail.\n",
      "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mpandas\u001b[39m\u001b[22m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mpandas\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[33m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m...\u001b[39m\u001b[22m\n",
      "\u001b[K\u001b[?25h‚úî Installation Succeeded\u001b[0m \n",
      "\u001b[33m\u001b[1mPipfile.lock (c2ee98) out of date, updating to (bedf65)...\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[33m\u001b[22m[dev-packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies...\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[33m\u001b[22m[packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies...\u001b[39m\u001b[22m\n",
      "\u001b[KBuilding requirements...\n",
      "\u001b[KResolving dependencies...\n",
      "\u001b[K\u001b[?25h\u001b[32m\u001b[22m‚úî Success!\u001b[39m\u001b[22m\u001b[0m \n",
      "\u001b[39m\u001b[1mUpdated Pipfile.lock (bedf65)!\u001b[39m\u001b[22m\n",
      "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (bedf65)...\u001b[39m\u001b[22m\n",
      "  üêç   \u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m\u001b[32m\u001b[1m‚ñâ\u001b[39m\u001b[22m 0/0 ‚Äî \u001b[30m\u001b[22m00:00:00\u001b[39m\u001b[22m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d5a0d7-b360-4ca3-8f88-cab51f532941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee66b447-45d8-441a-b3bd-301b75ddf0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krish</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudhanshu</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harsha</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  age  Experience  Salary\n",
       "0      Krish   31          10   30000\n",
       "1  Sudhanshu   30           8   25000\n",
       "2      Sunny   29           4   20000\n",
       "3       Paul   24           3   20000\n",
       "4     Harsha   21           1   15000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('files/test1.csv').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30b37ebb-81ae-453b-9200-49172d54a01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_csv('files/test1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "786be88d-01d3-4995-a65b-bef5ba935639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1345d83-3be6-4e0f-9cd1-af2285c5fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 23:35:50 WARN Utils: Your hostname, paco-System-Product-Name resolves to a loopback address: 127.0.1.1; using 192.168.1.74 instead (on interface wlp5s0)\n",
      "22/10/23 23:35:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 23:35:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "195479fa-b421-424d-ba9e-655e2484ee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.74:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2b50bf71c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7628e079-f1d4-47b6-8ed2-3480fc5b5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('files/test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38d1ac4-164c-45d9-b775-1429b62b3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      _c0|_c1|       _c2|   _c3|\n",
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de5d8ba4-0317-4bcf-965a-97efb98686c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('files/test1.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63cc6620-840b-4e54-a744-45466cad0b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fdd57b2-dd65-4325-a262-cdc6faa41257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "276d64b9-4ed4-4549-aa4f-0f2911e3f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7001a719-147b-4ba4-ba5a-cfea7c09392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/23 23:57:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91a21ff5-7320-4faa-adc9-887eb6e89e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.74:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2b50bf71c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38e3950c-ab33-43b4-a25f-472af2d9119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset\n",
    "\n",
    "pd_pyspark = spark.read.option('header', 'true').csv('files/test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8a08731-445b-4e8f-b373-0e670b60d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "\n",
    "df_pyspark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea4a49af-40ab-4ae3-aa76-942e4d96e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Read the dataset\n",
    "\n",
    "pd_pyspark = spark.read.option('header', 'true').csv('files/test1.csv', inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea4a67be-cdb6-4d7d-b33f-e243348a3b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('files/test1.csv', header=True, inferSchema=True)\n",
    "pd_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54751e50-6bdf-4f58-9a1b-22bc5facfd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98761b1f-f9bb-486d-be0f-d22c06aa3ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18c379b4-87f3-4f71-a2a6-1523146e3dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfb02456-b218-4645-b53a-1535b1e17037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
       " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n",
       " Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "522dff96-e931-493d-8f95-4004090ebf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55b983ed-c213-4fee-a633-ab7af8e1ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2d70b01-4588-4e6e-9753-ce732f75dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a345578-6e44-4b58-a60b-0191ca4afd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|    Krish|        10|\n",
      "|Sudhanshu|         8|\n",
      "|    Sunny|         4|\n",
      "|     Paul|         3|\n",
      "|   Harsha|         1|\n",
      "|  Shubham|         2|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc3c26fa-f2ab-442e-8e89-bd2a1e5b7a17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_pyspark\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df_pyspark['Name'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bf044a1-68ec-4f07-887f-27d51020997f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56ec202e-561a-4ece-8bae-74007ed5fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, age: string, Experience: string, Salary: string]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0762a13b-fb5c-48eb-b138-8bb195d0dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|Harsha|                21|                1|             15000|\n",
      "|    max| Sunny|                31|               10|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58f7b61b-73c6-440e-9444-b23316fb5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+-----------------------+\n",
      "|     Name|age|Experience|Salary|Experience After 2 year|\n",
      "+---------+---+----------+------+-----------------------+\n",
      "|    Krish| 31|        10| 30000|                     12|\n",
      "|Sudhanshu| 30|         8| 25000|                     10|\n",
      "|    Sunny| 29|         4| 20000|                      6|\n",
      "|     Paul| 24|         3| 20000|                      5|\n",
      "|   Harsha| 21|         1| 15000|                      3|\n",
      "|  Shubham| 23|         2| 18000|                      4|\n",
      "+---------+---+----------+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Adding columns in data frame\n",
    "\n",
    "df_pyspark.withColumn('Experience After 2 year', df_pyspark['Experience']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31acecbd-c0ec-4e1f-b5fd-868941c25db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('Experience After 2 year', df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35ab2495-67ae-43d3-a3e3-8ef13ab87e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+-----------------------+\n",
      "|     Name|age|Experience|Salary|Experience After 2 year|\n",
      "+---------+---+----------+------+-----------------------+\n",
      "|    Krish| 31|        10| 30000|                     12|\n",
      "|Sudhanshu| 30|         8| 25000|                     10|\n",
      "|    Sunny| 29|         4| 20000|                      6|\n",
      "|     Paul| 24|         3| 20000|                      5|\n",
      "|   Harsha| 21|         1| 15000|                      3|\n",
      "|  Shubham| 23|         2| 18000|                      4|\n",
      "+---------+---+----------+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "198832f8-ef1d-4534-9a3f-af66afce7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4066f78-49bb-44d9-a5a2-a58403afa51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbd2f6f9-313d-4e40-8901-33ec1df86ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "| New Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Rename the columns\n",
    "df_pyspark.withColumnRenamed('Name', 'New Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e61bc-b932-48ee-9b81-00427edbaa47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
